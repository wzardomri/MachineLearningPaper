{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "726f63a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omristeinberg-tatman/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from matplotlib import pyplot\n",
    "from keras.optimizers import SGD\n",
    "np.set_printoptions(threshold=np.sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4f93ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66670, 5) (33330, 5) (66670,) (33330,)\n"
     ]
    }
   ],
   "source": [
    "#define the data\n",
    "FullData = pd.read_csv(\"DFF_Verification_Data.csv\")\n",
    "\n",
    "x, y = FullData.values[:, 2:-1], FullData.values[:, -1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3333)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "n_features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e55ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(100, input_shape=(n_features,), activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(80, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(80, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(80, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(30, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(30, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(30, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(30, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "predictions = model(np.asarray(x_train).astype('float32')).numpy()\n",
    "#tf.nn.softmax(predictions).numpy()\n",
    "loss_fn = tf.keras.losses.MeanSquaredError(name='mean_squared_error')#tf.keras.losses.MeanAbsoluteError()#tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_fn(y_train[:1], predictions).numpy()\n",
    "opt = SGD(lr=0.01)\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc8c118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.1757e-04 - accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 0.0603 - accuracy: 0.9797\n",
      "Epoch 3/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 5.3078e-04 - accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 4.4183e-04 - accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "2084/2084 [==============================] - 4s 2ms/step - loss: 4.1805e-04 - accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "2084/2084 [==============================] - 4s 2ms/step - loss: 3.8269e-04 - accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 3.3526e-04 - accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "2084/2084 [==============================] - 4s 2ms/step - loss: 3.3970e-04 - accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 3.1070e-04 - accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.8082e-04 - accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.7657e-04 - accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.5803e-04 - accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.4930e-04 - accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.4012e-04 - accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.7181e-04 - accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.1316e-04 - accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.0714e-04 - accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 4.2846e-05 - accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.8529e-05 - accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.4667e-05 - accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.7495e-05 - accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.1889e-05 - accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.1456e-05 - accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.0115e-05 - accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 8.7219e-06 - accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 7.8300e-06 - accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 7.1697e-06 - accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 6.7289e-06 - accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 5.9142e-06 - accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 5.6797e-06 - accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 5.2471e-06 - accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 4.9773e-06 - accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 4.7226e-06 - accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 4.4718e-06 - accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 4.2741e-06 - accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 4.1025e-06 - accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 3.9311e-06 - accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 3.7545e-06 - accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 3.6462e-06 - accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 3.5156e-06 - accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 3.3983e-06 - accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 3.3297e-06 - accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 3.2034e-06 - accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 3.1325e-06 - accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 3.0437e-06 - accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 2.9627e-06 - accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 2.9010e-06 - accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.8327e-06 - accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.7733e-06 - accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "2084/2084 [==============================] - 4s 2ms/step - loss: 2.7092e-06 - accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.6630e-06 - accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.6075e-06 - accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.5608e-06 - accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.5112e-06 - accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.4672e-06 - accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.4241e-06 - accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.3830e-06 - accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.3429e-06 - accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.3091e-06 - accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.2753e-06 - accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.2421e-06 - accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.2104e-06 - accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.1775e-06 - accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.1499e-06 - accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.1220e-06 - accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.0945e-06 - accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.0662e-06 - accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.0401e-06 - accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 2.0191e-06 - accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.9941e-06 - accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.9733e-06 - accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.9504e-06 - accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.9299e-06 - accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.9102e-06 - accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.8909e-06 - accuracy: 1.0000\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.8719e-06 - accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.8532e-06 - accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.8360e-06 - accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.8192e-06 - accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.8023e-06 - accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.7871e-06 - accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.7694e-06 - accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.7573e-06 - accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.7423e-06 - accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.7280e-06 - accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.7150e-06 - accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.7014e-06 - accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.6884e-06 - accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.6749e-06 - accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.6640e-06 - accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.6513e-06 - accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.6395e-06 - accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.6276e-06 - accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.6169e-06 - accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.6059e-06 - accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.5956e-06 - accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.5836e-06 - accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.5750e-06 - accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.5654e-06 - accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.5541e-06 - accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.5461e-06 - accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.5369e-06 - accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.5277e-06 - accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.5189e-06 - accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.5094e-06 - accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.5016e-06 - accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.4922e-06 - accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.4844e-06 - accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.4772e-06 - accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.4684e-06 - accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.4611e-06 - accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.4525e-06 - accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.4455e-06 - accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.4388e-06 - accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.4308e-06 - accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.4231e-06 - accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.4167e-06 - accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.4100e-06 - accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.4024e-06 - accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3966e-06 - accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3898e-06 - accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3837e-06 - accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3769e-06 - accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3682e-06 - accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3650e-06 - accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3590e-06 - accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3528e-06 - accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3479e-06 - accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3411e-06 - accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3359e-06 - accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3307e-06 - accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3250e-06 - accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3195e-06 - accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3143e-06 - accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3086e-06 - accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.3036e-06 - accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.2984e-06 - accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.2932e-06 - accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.2884e-06 - accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.2834e-06 - accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.2785e-06 - accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "2084/2084 [==============================] - 3s 2ms/step - loss: 1.2739e-06 - accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2690e-06 - accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2639e-06 - accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2594e-06 - accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2542e-06 - accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2502e-06 - accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2453e-06 - accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2408e-06 - accuracy: 1.0000\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2369e-06 - accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2318e-06 - accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2277e-06 - accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2232e-06 - accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2194e-06 - accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2148e-06 - accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2112e-06 - accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2070e-06 - accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.2026e-06 - accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1986e-06 - accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1945e-06 - accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1907e-06 - accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1871e-06 - accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1833e-06 - accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1795e-06 - accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1748e-06 - accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1714e-06 - accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1674e-06 - accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1631e-06 - accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1602e-06 - accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1562e-06 - accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1525e-06 - accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1489e-06 - accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1453e-06 - accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1414e-06 - accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1382e-06 - accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "2084/2084 [==============================] - 2s 1ms/step - loss: 1.1347e-06 - accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "2084/2084 [==============================] - 2s 1ms/step - loss: 1.1311e-06 - accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "2084/2084 [==============================] - 2s 1ms/step - loss: 1.1279e-06 - accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1245e-06 - accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "2084/2084 [==============================] - 2s 1ms/step - loss: 1.1214e-06 - accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1180e-06 - accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1147e-06 - accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1113e-06 - accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1083e-06 - accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1050e-06 - accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "2084/2084 [==============================] - 3s 1ms/step - loss: 1.1019e-06 - accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "1921/2084 [==========================>...] - ETA: 0s - loss: 1.1106e-06 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-447c02059854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ec97971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.000, Test: 1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgKElEQVR4nO3df5SU1Z3n8ffHpummERdokCCN0klYJwxriBKC0TFONBMwP3SSsxndMSYeE9ZzNKNJPBmMmXGzm+yaH2c2YaNhTEISJ6POJEpkHIxGJ645K/5oIjENwgCK0mIEMShGiIDf/eN5Wouqavrp7mqq+/bndU6drnru81TdW9V8uH2fp+5VRGBmZuk6ot4VMDOzweWgNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnob0SRtkXRmvethNpgc9GZmiXPQm5WR1CTpG5K25bdvSGrKyyZJul3SLknPS/qlpCPysr+W9LSk3ZI2SDqjvi0xy4yqdwXMhqCrgPnAHCCA24AvAH8DfBboAibn+84HQtLxwKXA2yNim6QZQMPhrbZZde7Rm1X6S+C/R8T2iNgBfBH4aF62D5gKHBcR+yLil5FNGHUAaAJmSWqMiC0RsbkutTcr46A3q3QM8GTJ4yfzbQBfAzYBd0l6XNJigIjYBFwO/Ddgu6SbJR2D2RDgoDertA04ruTxsfk2ImJ3RHw2It4IfAD4TPdYfETcGBGn5scG8JXDW22z6hz0ZtAoqbn7BtwEfEHSZEmTgL8FfgQg6f2S3ixJwItkQzYHJB0v6d35Sdu9wJ68zKzuHPRmsJIsmLtvzUAH8CjwG+BXwJfyfWcCdwMvAauA6yLiXrLx+WuA54DfAkcDnz9sLTA7BHnhETOztLlHb2aWOAe9mVniHPRmZolz0JuZJW5IToEwadKkmDFjRr2rYWY2bKxevfq5iJhcrWxIBv2MGTPo6OiodzXMzIYNSU/2VOahGzOzxDnozcwSl1TQn/bVX/B/7tlY72qYmQ0pQ3KMvr+2797L7j/sr3c1zKwO9u3bR1dXF3v37q13VQZVc3MzbW1tNDY2Fj4mqaAXwlM6mI1MXV1djBs3jhkzZpDNOZeeiGDnzp10dXXR3t5e+Likhm4kcM6bjUx79+6ltbU12ZAHkERra2uf/2pJK+jJJgE3s5Ep5ZDv1p82phX0knv0ZmZl0gp6INynN7M62LVrF9ddd12fjzvrrLPYtWtX7StUIqmgx2P0ZlYnPQX9gQOHXmhs5cqVjB8/fpBqlUnsqhszs/pYvHgxmzdvZs6cOTQ2NnLkkUcydepU1qxZw7p16zjnnHPYunUre/fu5bLLLmPRokXA61O+vPTSSyxcuJBTTz2V+++/n2nTpnHbbbcxZsyYAdctqaA3MwP44r+sZd22F2v6nLOOOYqrP/DHPZZfc801dHZ2smbNGu69917e97730dnZ+dplkMuWLWPixIns2bOHt7/97Xz4wx+mtbX1oOfYuHEjN910E9/5znf4yEc+wi233ML5558/4LonFfTZyViP3ZhZ/c2bN++ga92XLFnC8uXLAdi6dSsbN26sCPr29nbmzJkDwEknncSWLVtqUpfEgt6XV5oZh+x5Hy5jx4597f69997L3XffzapVq2hpaeH000+vei18U1PTa/cbGhrYs2dPTeqS1MlY4ZOxZlYf48aNY/fu3VXLXnjhBSZMmEBLSwvr16/ngQceOKx1S6xHL19eaWZ10drayimnnMLs2bMZM2YMU6ZMea1swYIFLF26lBNOOIHjjz+e+fPnH9a6pRX0uEdvZvVz4403Vt3e1NTEHXfcUbWsexx+0qRJdHZ2vrb9iiuuqFm90hq68Ri9mVmFpIIePAWCmVm5pIJ+BMxnZGaHMBIur+5PG5MK+kz6H7SZVWpubmbnzp1Jh333fPTNzc19Os4nY80sCW1tbXR1dbFjx456V2VQda8w1RdpBb0nNTMbsRobG/u06tJIktTQjfB19GZm5QoFvaQFkjZI2iRpcZXyP5K0StIfJF3Rl2NryT16M7NKvQa9pAbgWmAhMAs4T9Ksst2eB/4K+Ho/jq0ZLyVoZlapSI9+HrApIh6PiFeAm4GzS3eIiO0R8TCwr6/H1pKXEjQzq1Qk6KcBW0sed+Xbiih8rKRFkjokdQzkrLnH6M3MDlYk6Kt9DalomhY+NiKuj4i5ETF38uTJBZ++7MX8hSkzswpFgr4LmF7yuA3YVvD5B3Js/7hDb2Z2kCJB/zAwU1K7pNHAucCKgs8/kGP7zJOamZlV6vULUxGxX9KlwJ1AA7AsItZKujgvXyrpDUAHcBTwqqTLgVkR8WK1YwepLdl19D4ba2Z2kELfjI2IlcDKsm1LS+7/lmxYptCxg8U9ejOzSol9M9ZfmDIzK5dW0Evu0ZuZlUkr6BkZ81GbmfVFUkGPx+jNzCokFfT+vpSZWaWkgh5wl97MrExSQZ+djHXSm5mVSivo8eWVZmbl0gp6LzxiZlYhraD3UoJmZhXSCnr36M3MKiQV9OCLbszMyiUV9F5K0MysUlpBX+8KmJkNQUkFfcZdejOzUkkFvU/GmplVSi/o610JM7MhJq2g91KCZmYV0gp69+jNzCqkFfR4jN7MrFxSQY+XEjQzq5BU0HspQTOzSmkFvb8xZWZWIamgNzOzSoWCXtICSRskbZK0uEq5JC3Jyx+VdGJJ2RZJv5G0RlJHLStfUQ98MtbMrNyo3naQ1ABcC7wH6AIelrQiItaV7LYQmJnf3gF8O//Z7U8j4rma1brnuno+ejOzMkV69POATRHxeES8AtwMnF22z9nADZF5ABgvaWqN69or9+jNzCoVCfppwNaSx135tqL7BHCXpNWSFvX0IpIWSeqQ1LFjx44C1ar2HA56M7NyRYK+2rUs5XF6qH1OiYgTyYZ3LpF0WrUXiYjrI2JuRMydPHlygWpVq6iHbszMyhUJ+i5gesnjNmBb0X0iovvndmA52VDQ4HCP3sysQpGgfxiYKald0mjgXGBF2T4rgAvyq2/mAy9ExDOSxkoaByBpLPBnQGcN638Q4bluzMzK9XrVTUTsl3QpcCfQACyLiLWSLs7LlwIrgbOATcDLwIX54VOA5cq+yTQKuDEiflbzVuQ8Rm9mVqnXoAeIiJVkYV66bWnJ/QAuqXLc48BbB1jHvnHQm5kdJKlvxvpkrJlZpbSC3kM3ZmYV0gv6elfCzGyISSvovZSgmVmFtILePXozswpJBT14jN7MrFxSQS8vJWhmViGtoK93BczMhqCkgh7w2I2ZWZmkgt4nY83MKqUV9LhDb2ZWLq2g91KCZmYV0gp63KM3MyuXVtB7rhszswpJBT34Onozs3JJBX3Wo3fUm5mVSivo610BM7MhKKmgNzOzSkkFvU/GmplVSivovZSgmVmFtILePXozswrpBX29K2FmNsSkFfReStDMrEJSQY979GZmFQoFvaQFkjZI2iRpcZVySVqSlz8q6cSix9aS57oxM6s0qrcdJDUA1wLvAbqAhyWtiIh1JbstBGbmt3cA3wbeUfDYmjl2Ygu3P/oMP7x/C+2TxjK2aRRHNo2iZXQDo0cdwagjRMMRQj19tarKZhXfNd+/ssRf5DKzIiRoGd1rLPdZkWecB2yKiMeziuhm4GygNKzPBm6IbID8AUnjJU0FZhQ4tmbOm3csd3T+lqtXrB2MpzczG1STjmyi4wtn1vx5iwT9NGBryeMusl57b/tMK3gsAJIWAYsAjj322ALVqjR9Ygt3f+ZdbNu1h2df3MtLf9jP7/9wgN+/sp99B17lwKvB/gPVx3aqbe3rid1qu/u6fjMrakxjw6A8b5GgrzbyUJ5ePe1T5NhsY8T1wPUAc+fO7Xc6Nhwhpk9sYfrElv4+hZlZUooEfRcwveRxG7Ct4D6jCxxrZmaDqMhVNw8DMyW1SxoNnAusKNtnBXBBfvXNfOCFiHim4LFmZjaIeu3RR8R+SZcCdwINwLKIWCvp4rx8KbASOAvYBLwMXHioY3t7zdWrVz8n6cl+tmkS8Fw/jx2u3OaRwW1O30Dae1xPBUrtm6SSOiJibr3rcTi5zSOD25y+wWpvWt+MNTOzCg56M7PEpRj019e7AnXgNo8MbnP6BqW9yY3Rm5nZwVLs0dsIJuleSb+T1FTvupgNFQ56S4akGcCfkH37+oOH8XVrPwuVWQ0lE/SHczrkw0nSdEm/kPSYpLWSLsu3T5T0c0kb858TSo65Mn8fNkh6b/1qPzCSGiQ9Iun2/PEh2wysBl4BfgF8rKRsuqRbJe2QtFPSt0rKPpm/t7slreueYltSSHpzyX4/kPSl/P7pkrok/bWk3wLflzRB0u35a/wuv99WcvxESd+XtC0v/2m+vVPSB/L74yXdImm/pMclnZz65yzp0/nvdaekmyQ1p9ZmScskbZfUWbKtz22UdJKk3+RlS6Se5tatIiKG/Y3sy1ibgTeSTbvwa2BWvetVo7ZNBU7M748D/h2YBXwVWJxvXwx8Jb8/K29/E9Cevy8N9W5HP9v+GeBG4Pb8cW9t3gT8DdlEevuAKfnvxq+B/w2MBZqBU/Pj/jPwNPB2snmZ3gwcl5cF8OaSuvwA+FJ+/3RgP/CV/H0eA7QCHwZa8s/px8BPS47/V+CfgAlAI/CufPvngH/K7/8Q+Bbwm/z3eHzKnzPZpIdPAGPyx/8MfDy1NgOnAScCnSXb+txG4CHg5Px39Q5gYeE61PtNqNEbeTJwZ8njK4Er612vQWrrbWTz+28ApubbpgIbqrWd7FvJJ9e73v1oZxtwD/BuXg/6Q7V5KVm4T8rbvAX4dP67sQMYVeU17gQu6+H1ewv6V4DmQ9R/DvC7krq+Ckyost8xwO6S0PsJ8LmS8mQ/Z16f3XYi2bf0bwf+LMU2k03ZXhr0fWpjvs/6ku3nAX9f9PVTGbrpaZrkpORj0G8DHgSmRDafEPnPo/PdUnkvvkHW2321ZNuh2nw8cFdEPEfW5gfIhm+mA09GxP4qrzGdrMfUHzsiYm/3A0ktkv5e0pOSXgTuA8YrW3xnOvB8RPyu/EkiYhvw/4CLgOfJ1mu4QNJ3JY3tpc3D+nOOiKeBrwNPAc+QzZF1Fwm3uURf2zgtv1++vZBUgr7wdMjDlaQjgVuAyyPixUPtWmXbsHovJL0f2B4RqwseMopsnYN35WPm5wHvB94KPAsc28MJ063Am3p4zpfJhmG6vaGsvPw9/SzZfzbviIijyP5ch+zz2ApMlDS+h9f6YV7fOcAjETEb+D3Zn/Q9SeFznkD2H1s72V82YyWdf6hDqmwbVm0uYMBTvleTStAXmUp52JLUSBby/xgRt+abn1W2ihf5z+359hTei1OAD0raAtwMvFvSj+i5zf8h/zmLLCwfBP4C+CVwDllv8RpJY/OTfafk+38XuCI/ySVJb5bUPTHUGuC/5CeEFwDv6qXO44A9wC5JE4GruwvyHtsdwHX5SdtGSaeVHPtT4D8CB8jG6CEbwjnxEG1O4XM+E3giInZExD7gVuCdpN3mbn1tY1d+v3x7IakEfbLTIedn1r8HPBYRf1dStILXryz5GNnYfff2cyU1SWonW8f3ocNV31qIiCsjoi0iZpB9lv8WEefTc5unAy+R9d7HkM3i9zOy0DwP+ADZidanyP7B/EX+Oj8Gvkx2wnc3WeBOzJ/zsvy4XcBf5mWH8o38tZ8jGzb6WVn5R8nOIawn+0d9eUl795AFewPZiViAM8iW3Ez2cyb7PObnw14ia/NjpN3mbn1qY95Z2C1pfv5eXVByTO/qfZKihic7ziK7ImUzcFW961PDdp1K9ifao2S9zDV5W1vJTlZuzH9OLDnmqvx92EAfzswPxRvZic/uk7HJthn4W7Irczryz/qnZFfoJNvmvA1fJPvPrxP4B7KrTZJqM3AT2V+V+8g6Ghf1p43A3Px92kzWiVHROngKBLM6y4d6HgE+GhH31bs+lp5Uhm7MhiVJnyQ7WXuHQ94Gi3v0ZmaJc4/ezCxxQ3IypkmTJsWMGTPqXQ0zs2Fj9erVz0XE5GplvQa9pGVkX+bYHtkXOcrLBXyT7EqQl4GPR8Sv8rIFeVkD8N2IuKZIhWfMmEFHR0eRXc3MDJD0ZE9lRYZufgAsOET5QrJrPWcCi4Bv5y/aAFybl88CzpM0q1iVzcysVnrt0UfEffkcKz05G7ghsrO6D+RTrU4lm8RnU0Q8DiDp5nzfdQOudQ/2vHKADc/upj8nmAdySrr/57P7/6r9fc16tHMgJ/z7e+RArjGI/r7qgF6zn8fVoZ0De81+HleH36GBfZ79O3h0QwOnzpzU/xfuQS3G6A81CU/59nf09CSSFpH9RcCxxx7br4r8j39dx40PPtWvY83M6m3SkU10fOHMmj9vLYK+JpPwRMT15Avjzp07t1//Hb6wZx9vOKqZ//Xh/9Sfw4HqlS50XB/WAKjda/b7JVE/X3Vgr3m4Dxxe7RzQ71A/Dx1AMwfwHg3OZxKvHqDh5efRgX39ev6h4rHHHjtkeXNzM21tbTQ2NhZ+zloEfU+T8IzuYfvgCRjb1MCfHn907/uaWVKeeOIJxh09kdbW1gH9pzmURQQ7d+6kq6uL9vb2wsfV4jr6FWTzZ0vSfLI5pZ+hDhONBZHsB2xmh7Z3796kQx6yv/paW1vZu3dv7zuXKHJ55U1kE0tNktRFNv1qI0BELAVWkl1auYns8soL87L9ki4lWyGlAVgWEWv7VLt+SPcjNrPepBzy3frTxiJX3ZzXS3kAl/RQtpLsP4LDImJgY6tmZilKagqEiP6ffDMzG4hdu3Zx3XXX9fm4s846i127dtW+QiXSCvrkVhUzs+Gip6A/cODAIY9buXIl48ePH6RaZYbkXDf95aEbMwP44r+sZd22Qy2t3HezjjmKqz/wxz2WL168mM2bNzNnzhwaGxs58sgjmTp1KmvWrGHdunWcc845bN26lb1793LZZZexaNEi4PUpX1566SUWLlzIqaeeyv3338+0adO47bbbGDNmzIDrnliP3sysPq655hre9KY3sWbNGr72ta/x0EMP8eUvf5l167LJAJYtW8bq1avp6OhgyZIl7Ny5s+I5Nm7cyCWXXMLatWsZP348t9xyS03qlmCP3l16s5HuUD3vw2XevHkHXeu+ZMkSli9fDsDWrVvZuHEjra2tBx3T3t7OnDlzADjppJPYsmVLTeqSVNBD+FSsmQ0JY8eOfe3+vffey913382qVatoaWnh9NNPr3otfFNT02v3Gxoa2LNnT03qktTQDXiM3szqY9y4cezevbtq2QsvvMCECRNoaWlh/fr1PPDAA4e1bkn16H0y1szqpbW1lVNOOYXZs2czZswYpkyZ8lrZggULWLp0KSeccALHH3888+fPP6x1Syvo8XX0ZlY/N954Y9XtTU1N3HHHHVXLusfhJ02aRGdn52vbr7jiiprVK6mhGy90bmZWKa2gx0M3Zmbl0gr68KRmZiPZSPirvj9tTCvowV16sxGqubmZnTt3Jh323fPRNzc39+m4pE7Ggnv0ZiNVW1sbXV1d7Nixo95VGVTdK0z1RVJBHxHu0JuNUI2NjX1adWkkSWroBtyjNzMrl1TQJzw0Z2bWb2kFvdeMNTOrkFbQ+/JKM7MK6QW9k97M7CCFgl7SAkkbJG2StLhK+QRJyyU9KukhSbNLyi6T1ClpraTLa1j3CkF4rhszszK9Br2kBuBaYCEwCzhP0qyy3T4PrImIE4ALgG/mx84GPgnMA94KvF/SzNpVv1qFB/XZzcyGnSI9+nnApoh4PCJeAW4Gzi7bZxZwD0BErAdmSJoCvAV4ICJejoj9wP8F/rxmtS/jMXozs0pFgn4asLXkcVe+rdSvgQ8BSJoHHAe0AZ3AaZJaJbUAZwHTq72IpEWSOiR19PebbZ7UzMysUpGgrxad5VesXwNMkLQG+BTwCLA/Ih4DvgL8HPgZ2X8I+6u9SERcHxFzI2Lu5MmTC1a/l1qZmVmhKRC6OLgX3gZsK90hIl4ELgRQdiH7E/mNiPge8L287H/mzzcospOxSV1IZGY2YEVS8WFgpqR2SaOBc4EVpTtIGp+XAXwCuC8PfyQdnf88lmx456ZaVb6cL680M6vUa48+IvZLuhS4E2gAlkXEWkkX5+VLyU663iDpALAOuKjkKW6R1ArsAy6JiN/VuhGv1RUHvZlZuUKzV0bESmBl2balJfdXAVUvm4yIPxlIBfsiwtfRm5mVS25A2z16M7ODJRX0vujGzKxSWkEfePZKM7MyaQV9vStgZjYEJRX0RPhUrJlZmaSC3pdXmplVSivoPamZmVmFtILeSwmamVVIKujBPXozs3JJBb3nujEzq5Rc0JuZ2cHSCnrAgzdmZgdLK+gjPHRjZlYmqaAH9+fNzMolFfQ+GWtmVimtoMfz0ZuZlUsq6ME9ejOzckkFvYduzMwqpRX09a6AmdkQVCjoJS2QtEHSJkmLq5RPkLRc0qOSHpI0u6Ts05LWSuqUdJOk5lo2oJTXjDUzq9Rr0EtqAK4FFgKzgPMkzSrb7fPAmog4AbgA+GZ+7DTgr4C5ETEbaADOrV31Dxbg6yvNzMoU6dHPAzZFxOMR8QpwM3B22T6zgHsAImI9MEPSlLxsFDBG0iigBdhWk5pX42mKzcwqFAn6acDWksdd+bZSvwY+BCBpHnAc0BYRTwNfB54CngFeiIi7qr2IpEWSOiR17Nixo2+tyGULjzjqzcxKFQn6aslZft7zGmCCpDXAp4BHgP2SJpD1/tuBY4Cxks6v9iIRcX1EzI2IuZMnTy5a//LncI/ezKzMqAL7dAHTSx63UTb8EhEvAhcCKOtSP5Hf3gs8ERE78rJbgXcCPxpwzXvgDr2Z2cGK9OgfBmZKapc0muxk6orSHSSNz8sAPgHcl4f/U8B8SS35fwBnAI/VrvoHCzxGb2ZWrtcefUTsl3QpcCfZVTPLImKtpIvz8qXAW4AbJB0A1gEX5WUPSvoJ8CtgP9mQzvWD0hI8H72ZWTVFhm6IiJXAyrJtS0vurwJm9nDs1cDVA6hjYV4z1sysUlrfjPXllWZmFZILeie9mdnBkgp6wFMgmJmVSSrovZSgmVmlpIIePHJjZlYuqaD31ZVmZpXSCnovPGJmViGtoPeasWZmFdIKevfozcwqpBX0OOjNzMqlFfReYsrMrEJSQQ/u0ZuZlUss6L3wiJlZuaSC3tMUm5lVSivo8dCNmVm5tII+fB29mVm5tIIe9+jNzMqlFfReeMTMrEJiQe+lBM3MyhUKekkLJG2QtEnS4irlEyQtl/SopIckzc63Hy9pTcntRUmX17gNZmZ2CL0uDi6pAbgWeA/QBTwsaUVErCvZ7fPAmoj4c0l/lO9/RkRsAOaUPM/TwPLaNuF1vrrSzKxSkR79PGBTRDweEa8ANwNnl+0zC7gHICLWAzMkTSnb5wxgc0Q8OcA698yTmpmZVSgS9NOArSWPu/JtpX4NfAhA0jzgOKCtbJ9zgZt6ehFJiyR1SOrYsWNHgWpVytYGd9KbmZUqEvTVkrN8lOQaYIKkNcCngEeA/a89gTQa+CDw455eJCKuj4i5ETF38uTJBapV9TncozczK9PrGD1ZD356yeM2YFvpDhHxInAhgLLLXp7Ib90WAr+KiGcHVNteZD16MzMrVaRH/zAwU1J73jM/F1hRuoOk8XkZwCeA+/Lw73Yehxi2qRUvPGJmVqnXHn1E7Jd0KXAn0AAsi4i1ki7Oy5cCbwFukHQAWAdc1H28pBayK3b+6yDU/+C64uvozczKFRm6ISJWAivLti0tub8KmNnDsS8DrQOoY5845s3MDlYo6IeLh686k8aGpL7sa2Y2YEkF/bjmxnpXwcxsyHH318wscQ56M7PEKYbg+nuSdgD9nSphEvBcDaszHLjNI4PbnL6BtPe4iKj6bdMhGfQDIakjIubWux6Hk9s8MrjN6Rus9nroxswscQ56M7PEpRj019e7AnXgNo8MbnP6BqW9yY3Rm5nZwVLs0ZuZWQkHvZlZ4pIJ+t4WMB+uJE2X9AtJj0laK+myfPtEST+XtDH/OaHkmCvz92GDpPfWr/YDI6lB0iOSbs8fJ93mfLrvn0han3/eJ4+ANn86/73ulHSTpObU2ixpmaTtkjpLtvW5jZJOkvSbvGyJ+jJVb0QM+xvZ9MmbgTcCo8mWNpxV73rVqG1TgRPz++OAfydbo/erwOJ8+2LgK/n9WXn7m4D2/H1pqHc7+tn2zwA3Arfnj5NuM/BD4BP5/dHA+JTbTLYk6RPAmPzxPwMfT63NwGnAiUBnybY+txF4CDiZbJLeO4CFReuQSo++yALmw1JEPBMRv8rv7wYeI/sHcjZZMJD/PCe/fzZwc0T8ISKeADaRvT/DiqQ24H3Ad0s2J9tmSUeRBcL3ACLilYjYRcJtzo0CxkgaBbSQrV6XVJsj4j7g+bLNfWqjpKnAURGxKrLUv6HkmF6lEvRFFjAf9iTNAN4GPAhMiYhnIPvPADg63y2V9+IbwOeAV0u2pdzmNwI7gO/nw1XflTSWhNscEU8DXweeAp4BXoiIu0i4zSX62sZp+f3y7YWkEvRFFjAf1iQdCdwCXB4HL9NYsWuVbcPqvZD0fmB7RKwuekiVbcOqzWQ92xOBb0fE24Dfk/1J35Nh3+Z8XPpssiGKY4Cxks4/1CFVtg2rNhfQUxsH1PZUgr7XBcyHM0mNZCH/jxFxa7752fzPOfKf2/PtKbwXpwAflLSFbBju3ZJ+RNpt7gK6IuLB/PFPyII/5TafCTwRETsiYh9wK/BO0m5zt762sSu/X769kFSCvtcFzIer/Mz694DHIuLvSopWAB/L738MuK1k+7mSmiS1ky3x+NDhqm8tRMSVEdEWETPIPst/i4jzSbvNvwW2Sjo+33QG2frLybaZbMhmvqSW/Pf8DLJzUCm3uVuf2pgP7+yWND9/ry4oOaZ39T4jXcMz22eRXZGyGbiq3vWpYbtOJfsT7VFgTX47i2wd3nuAjfnPiSXHXJW/Dxvow5n5oXgDTuf1q26SbjMwB+jIP+ufAhNGQJu/CKwHOoF/ILvaJKk2AzeRnYPYR9Yzv6g/bQTm5u/TZuBb5DMbFLl5CgQzs8SlMnRjZmY9cNCbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mlrj/DxURqLmnvyUqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot loss during training\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.legend()\n",
    "# plot accuracy during training\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy')\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3413ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DFFverificationmodel.pkl', 'wb') as f:\n",
    "    pickle.dump({'weights': model.get_weights(), 'history': history.history}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bda0877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights and history from the file and evaluate the model\n",
    "with open('DFFverificationmodel.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "model.set_weights(data['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81e8512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0:\n",
      "  Total: 16771\n",
      "  Correct: 16771\n",
      "  True 0: 16771\n",
      "  False 1: 0\n",
      "  Accuracy: 1.0\n",
      "Class 1:\n",
      "  Total: 16559\n",
      "  Correct: 16559\n",
      "  True 1: 16559\n",
      "  False 0: 0\n",
      "  Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.round(y_pred).flatten()\n",
    "\n",
    "# compute class-wise accuracy and confusion matrix\n",
    "class_0_correct = 0\n",
    "class_0_total = 0\n",
    "class_0_true_0 = 0\n",
    "class_0_false_1 = 0\n",
    "class_1_correct = 0\n",
    "class_1_total = 0\n",
    "class_1_true_1 = 0\n",
    "class_1_false_0 = 0\n",
    "for i in range(len(y_test)):\n",
    "    true_class = y_test[i]\n",
    "    pred_class = y_pred_classes[i]\n",
    "    if true_class == 0:\n",
    "        class_0_total += 1\n",
    "        if pred_class == 0:\n",
    "            class_0_correct += 1\n",
    "            class_0_true_0 += 1\n",
    "        else:\n",
    "            class_0_false_1 += 1\n",
    "    elif true_class == 1:\n",
    "        class_1_total += 1\n",
    "        if pred_class == 1:\n",
    "            class_1_correct += 1\n",
    "            class_1_true_1 += 1\n",
    "        else:\n",
    "            class_1_false_0 += 1\n",
    "\n",
    "class_0_accuracy = class_0_correct / class_0_total\n",
    "class_1_accuracy = class_1_correct / class_1_total\n",
    "\n",
    "print(\"Class 0:\")\n",
    "print(f\"  Total: {class_0_total}\")\n",
    "print(f\"  Correct: {class_0_correct}\")\n",
    "print(f\"  True 0: {class_0_true_0}\")\n",
    "print(f\"  False 1: {class_0_false_1}\")\n",
    "print(f\"  Accuracy: {class_0_accuracy}\")\n",
    "print(\"Class 1:\")\n",
    "print(f\"  Total: {class_1_total}\")\n",
    "print(f\"  Correct: {class_1_correct}\")\n",
    "print(f\"  True 1: {class_1_true_1}\")\n",
    "print(f\"  False 0: {class_1_false_0}\")\n",
    "print(f\"  Accuracy: {class_1_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217fad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
