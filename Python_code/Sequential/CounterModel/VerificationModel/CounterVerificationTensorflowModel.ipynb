{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "90c6570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from matplotlib import pyplot\n",
    "from keras.optimizers import SGD\n",
    "np.set_printoptions(threshold=np.sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8195a804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 4) (10000, 4) (90000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#define the data\n",
    "FullData = pd.read_csv(\"counter_Verification_Data.csv\")\n",
    "\n",
    "x, y = FullData.values[:, 1:-1], FullData.values[:, -1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "n_features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c317a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(100, input_shape=(n_features,), activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(80, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(80, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(80, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(30, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(30, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(30, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(30, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "predictions = model(np.asarray(x_train).astype('float32')).numpy()\n",
    "#tf.nn.softmax(predictions).numpy()\n",
    "loss_fn = tf.keras.losses.MeanSquaredError(name='mean_squared_error')#tf.keras.losses.MeanAbsoluteError()#tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_fn(y_train[:1], predictions).numpy()\n",
    "opt = SGD(lr=0.01)\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b40ef39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0125 - accuracy: 0.9945\n",
      "Epoch 2/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0123 - accuracy: 0.9945\n",
      "Epoch 3/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0133 - accuracy: 0.9940\n",
      "Epoch 4/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0124 - accuracy: 0.9944\n",
      "Epoch 5/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0126 - accuracy: 0.9946\n",
      "Epoch 6/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0130 - accuracy: 0.9943\n",
      "Epoch 7/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0125 - accuracy: 0.9947\n",
      "Epoch 8/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0128 - accuracy: 0.9944\n",
      "Epoch 9/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0121 - accuracy: 0.9945\n",
      "Epoch 10/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0118 - accuracy: 0.9947\n",
      "Epoch 11/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0126 - accuracy: 0.9947\n",
      "Epoch 12/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0120 - accuracy: 0.9950\n",
      "Epoch 13/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0116 - accuracy: 0.9945\n",
      "Epoch 14/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0122 - accuracy: 0.9946\n",
      "Epoch 15/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0116 - accuracy: 0.9944\n",
      "Epoch 16/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0127 - accuracy: 0.9945\n",
      "Epoch 17/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0118 - accuracy: 0.9948\n",
      "Epoch 18/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0114 - accuracy: 0.9944\n",
      "Epoch 19/1000\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0127 - accuracy: 0.9942\n",
      "Epoch 20/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0115 - accuracy: 0.9947\n",
      "Epoch 21/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0109 - accuracy: 0.9949\n",
      "Epoch 22/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0121 - accuracy: 0.9947\n",
      "Epoch 23/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0112 - accuracy: 0.9951\n",
      "Epoch 24/1000\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0116 - accuracy: 0.9947\n",
      "Epoch 25/1000\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0116 - accuracy: 0.9948\n",
      "Epoch 26/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0110 - accuracy: 0.9948\n",
      "Epoch 27/1000\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0112 - accuracy: 0.9949\n",
      "Epoch 28/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0117 - accuracy: 0.9948\n",
      "Epoch 29/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0115 - accuracy: 0.9949\n",
      "Epoch 30/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0119 - accuracy: 0.9947\n",
      "Epoch 31/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0114 - accuracy: 0.9948\n",
      "Epoch 32/1000\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0114 - accuracy: 0.9947\n",
      "Epoch 33/1000\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0108 - accuracy: 0.9949\n",
      "Epoch 34/1000\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0110 - accuracy: 0.9952\n",
      "Epoch 35/1000\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0106 - accuracy: 0.9948\n",
      "Epoch 36/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0116 - accuracy: 0.9947\n",
      "Epoch 37/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0115 - accuracy: 0.9949\n",
      "Epoch 38/1000\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0103 - accuracy: 0.9951\n",
      "Epoch 39/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0118 - accuracy: 0.9948\n",
      "Epoch 40/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0111 - accuracy: 0.9948\n",
      "Epoch 41/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0109 - accuracy: 0.9948\n",
      "Epoch 42/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0114 - accuracy: 0.9947\n",
      "Epoch 43/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0111 - accuracy: 0.9949\n",
      "Epoch 44/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0107 - accuracy: 0.9950\n",
      "Epoch 45/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0110 - accuracy: 0.9949\n",
      "Epoch 46/1000\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0113 - accuracy: 0.9948\n",
      "Epoch 47/1000\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0118 - accuracy: 0.9947\n",
      "Epoch 48/1000\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0109 - accuracy: 0.9948\n",
      "Epoch 49/1000\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0114 - accuracy: 0.9952\n",
      "Epoch 50/1000\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0113 - accuracy: 0.9949\n",
      "Epoch 51/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0106 - accuracy: 0.9949\n",
      "Epoch 52/1000\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0110 - accuracy: 0.9948\n",
      "Epoch 53/1000\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0103 - accuracy: 0.9952\n",
      "Epoch 54/1000\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0106 - accuracy: 0.9952\n",
      "Epoch 55/1000\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0109 - accuracy: 0.9951\n",
      "Epoch 56/1000\n",
      "1567/3125 [==============>...............] - ETA: 2s - loss: 0.0112 - accuracy: 0.9949"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-a39c1fd9836e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fe0c929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.999, Test: 1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot loss during training\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.legend()\n",
    "# plot accuracy during training\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy')\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1886fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Counterverificationmodel.pkl', 'wb') as f:\n",
    "    pickle.dump({'weights': model.get_weights(), 'history': history.history}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2391c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights and history from the file and evaluate the model\n",
    "with open('Counterverificationmodel.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "model.set_weights(data['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "703a2806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "313\n",
      "441\n",
      "596\n",
      "761\n",
      "762\n",
      "767\n",
      "1219\n",
      "1277\n",
      "1530\n",
      "1596\n",
      "1750\n",
      "2080\n",
      "2315\n",
      "2493\n",
      "2674\n",
      "2703\n",
      "2770\n",
      "3479\n",
      "3565\n",
      "4004\n",
      "4014\n",
      "4335\n",
      "4595\n",
      "4888\n",
      "5002\n",
      "5559\n",
      "5755\n",
      "5756\n",
      "5835\n",
      "5956\n",
      "6186\n",
      "6543\n",
      "7092\n",
      "7149\n",
      "7237\n",
      "7565\n",
      "7771\n",
      "7956\n",
      "8182\n",
      "8281\n",
      "8389\n",
      "8401\n",
      "8415\n",
      "8927\n",
      "9126\n",
      "9221\n",
      "10047\n",
      "10198\n",
      "10248\n",
      "10981\n",
      "12148\n",
      "12211\n",
      "12267\n",
      "12378\n",
      "12747\n",
      "13494\n",
      "13632\n",
      "13682\n",
      "13851\n",
      "13894\n",
      "14148\n",
      "14276\n",
      "14284\n",
      "14527\n",
      "14630\n",
      "14766\n",
      "14777\n",
      "15033\n",
      "15112\n",
      "15197\n",
      "15238\n",
      "15401\n",
      "15455\n",
      "15573\n",
      "15582\n",
      "15728\n",
      "16376\n",
      "16424\n",
      "16584\n",
      "16667\n",
      "16696\n",
      "16940\n",
      "17030\n",
      "17089\n",
      "17227\n",
      "17438\n",
      "17567\n",
      "18036\n",
      "18296\n",
      "18303\n",
      "18733\n",
      "18830\n",
      "19112\n",
      "19184\n",
      "19527\n",
      "19768\n",
      "19832\n",
      "20031\n",
      "20231\n",
      "20678\n",
      "20691\n",
      "20858\n",
      "21266\n",
      "21269\n",
      "21590\n",
      "21665\n",
      "21780\n",
      "21848\n",
      "22492\n",
      "22588\n",
      "22648\n",
      "22756\n",
      "22781\n",
      "22802\n",
      "22887\n",
      "23175\n",
      "23503\n",
      "23753\n",
      "23848\n",
      "23890\n",
      "24002\n",
      "24320\n",
      "24351\n",
      "24449\n",
      "24544\n",
      "24774\n",
      "24894\n",
      "24903\n",
      "25140\n",
      "25247\n",
      "25260\n",
      "25369\n",
      "25463\n",
      "25513\n",
      "25586\n",
      "25601\n",
      "26084\n",
      "26302\n",
      "26543\n",
      "26607\n",
      "26739\n",
      "26798\n",
      "26912\n",
      "27164\n",
      "27234\n",
      "27404\n",
      "27529\n",
      "27772\n",
      "27786\n",
      "27834\n",
      "27952\n",
      "28450\n",
      "28459\n",
      "29032\n",
      "29080\n",
      "29264\n",
      "29612\n",
      "29752\n",
      "30002\n",
      "30353\n",
      "30690\n",
      "31279\n",
      "31324\n",
      "31349\n",
      "31512\n",
      "31551\n",
      "31597\n",
      "31836\n",
      "31985\n",
      "32121\n",
      "32242\n",
      "32359\n",
      "32638\n",
      "33206\n",
      "Class 0:\n",
      "  Total: 16694\n",
      "  Correct: 16519\n",
      "  True 0: 16519\n",
      "  False 1: 175\n",
      "  Accuracy: 0.9895171918054391\n",
      "Class 1:\n",
      "  Total: 16636\n",
      "  Correct: 16636\n",
      "  True 1: 16636\n",
      "  False 0: 0\n",
      "  Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.round(y_pred).flatten()\n",
    "\n",
    "# compute class-wise accuracy and confusion matrix\n",
    "class_0_correct = 0\n",
    "class_0_total = 0\n",
    "class_0_true_0 = 0\n",
    "class_0_false_1 = 0\n",
    "class_1_correct = 0\n",
    "class_1_total = 0\n",
    "class_1_true_1 = 0\n",
    "class_1_false_0 = 0\n",
    "for i in range(len(y_test)):\n",
    "    true_class = y_test[i]\n",
    "    pred_class = y_pred_classes[i]\n",
    "    if true_class == 0:\n",
    "        class_0_total += 1\n",
    "        if pred_class == 0:\n",
    "            class_0_correct += 1\n",
    "            class_0_true_0 += 1\n",
    "        else:\n",
    "            class_0_false_1 += 1\n",
    "            print(i)\n",
    "    elif true_class == 1:\n",
    "        class_1_total += 1\n",
    "        if pred_class == 1:\n",
    "            class_1_correct += 1\n",
    "            class_1_true_1 += 1\n",
    "        else:\n",
    "            class_1_false_0 += 1\n",
    "\n",
    "class_0_accuracy = class_0_correct / class_0_total\n",
    "class_1_accuracy = class_1_correct / class_1_total\n",
    "\n",
    "print(\"Class 0:\")\n",
    "print(f\"  Total: {class_0_total}\")\n",
    "print(f\"  Correct: {class_0_correct}\")\n",
    "print(f\"  True 0: {class_0_true_0}\")\n",
    "print(f\"  False 1: {class_0_false_1}\")\n",
    "print(f\"  Accuracy: {class_0_accuracy}\")\n",
    "print(\"Class 1:\")\n",
    "print(f\"  Total: {class_1_total}\")\n",
    "print(f\"  Correct: {class_1_correct}\")\n",
    "print(f\"  True 1: {class_1_true_1}\")\n",
    "print(f\"  False 0: {class_1_false_0}\")\n",
    "print(f\"  Accuracy: {class_1_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a7c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
