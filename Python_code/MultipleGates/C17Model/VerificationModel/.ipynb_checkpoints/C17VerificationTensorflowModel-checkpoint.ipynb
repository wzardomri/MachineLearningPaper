{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1190ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from matplotlib import pyplot\n",
    "from keras.optimizers import SGD\n",
    "np.set_printoptions(threshold=np.sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa75e55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46669, 7) (23331, 7) (46669,) (23331,)\n"
     ]
    }
   ],
   "source": [
    "#define the data\n",
    "FullData = pd.read_csv(\"C17_Verification_Data.csv\")\n",
    "\n",
    "x, y = FullData.values[:, 2:-1], FullData.values[:, -1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3333)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "n_features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66b79293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(100, input_shape=(n_features,), activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(80, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(80, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(80, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(30, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(30, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(30, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(30, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(5, activation= \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "predictions = model(np.asarray(x_train).astype('float32')).numpy()\n",
    "#tf.nn.softmax(predictions).numpy()\n",
    "loss_fn = tf.keras.losses.MeanSquaredError(name='mean_squared_error')#tf.keras.losses.MeanAbsoluteError()#tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_fn(y_train[:1], predictions).numpy()\n",
    "opt = SGD(lr=0.01)\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4ffbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 0.6793 - accuracy: 0.6268\n",
      "Epoch 2/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 0.0572 - accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 9.8917e-04 - accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.8511e-04 - accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.0398e-04 - accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.0158e-04 - accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 2.3911e-04 - accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.9659e-04 - accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.6442e-04 - accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.4260e-04 - accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.2515e-04 - accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.1080e-04 - accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 9.8808e-05 - accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 8.9176e-05 - accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 8.0962e-05 - accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 7.4410e-05 - accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.8512e-05 - accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.3451e-05 - accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.9151e-05 - accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.5383e-05 - accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.1741e-05 - accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.8642e-05 - accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.5856e-05 - accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.3566e-05 - accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.1162e-05 - accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.9219e-05 - accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.7398e-05 - accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.5628e-05 - accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.4033e-05 - accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "1459/1459 [==============================] - 1s 1ms/step - loss: 3.2663e-05 - accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.1291e-05 - accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.0053e-05 - accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 2.8610e-05 - accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 2.7704e-05 - accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 2.6856e-05 - accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 2.5868e-05 - accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 2.4917e-05 - accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 2.4219e-05 - accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 2.3321e-05 - accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 2.2720e-05 - accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 2.1998e-05 - accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 2.1236e-05 - accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 2.0538e-05 - accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 2.0030e-05 - accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.9528e-05 - accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.8951e-05 - accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.8453e-05 - accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.7987e-05 - accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.7588e-05 - accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.7060e-05 - accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.6601e-05 - accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.6265e-05 - accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.5991e-05 - accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.5481e-05 - accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.5085e-05 - accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.4780e-05 - accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.4513e-05 - accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.4302e-05 - accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.3894e-05 - accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.3580e-05 - accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.3310e-05 - accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.3004e-05 - accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.2760e-05 - accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.2601e-05 - accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.2376e-05 - accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.2042e-05 - accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.1906e-05 - accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.1686e-05 - accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.1397e-05 - accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.1243e-05 - accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.1086e-05 - accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.0861e-05 - accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.0684e-05 - accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.0452e-05 - accuracy: 1.0000\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.0416e-05 - accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 1.0127e-05 - accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 9.9781e-06 - accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 9.8296e-06 - accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 9.7057e-06 - accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 9.6029e-06 - accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 9.3952e-06 - accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 9.2083e-06 - accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 9.1220e-06 - accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 9.0102e-06 - accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 8.8629e-06 - accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 8.6691e-06 - accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 8.6467e-06 - accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 8.5138e-06 - accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 8.3884e-06 - accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 8.2548e-06 - accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 8.1894e-06 - accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 8.0565e-06 - accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 7.9065e-06 - accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 7.8927e-06 - accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 7.7267e-06 - accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 7.6528e-06 - accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 7.5970e-06 - accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 7.4344e-06 - accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 7.3421e-06 - accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 7.2831e-06 - accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 7.1770e-06 - accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "1459/1459 [==============================] - 1s 1ms/step - loss: 7.0468e-06 - accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.9944e-06 - accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "1459/1459 [==============================] - 1s 985us/step - loss: 6.9643e-06 - accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "1459/1459 [==============================] - 1s 1ms/step - loss: 6.8129e-06 - accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.7850e-06 - accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.6867e-06 - accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.6494e-06 - accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.5125e-06 - accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.4737e-06 - accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.4055e-06 - accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.3407e-06 - accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.2561e-06 - accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.1989e-06 - accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.1524e-06 - accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.0574e-06 - accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 6.0026e-06 - accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.8971e-06 - accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.9133e-06 - accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.8210e-06 - accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.8043e-06 - accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.7115e-06 - accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.6871e-06 - accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.5967e-06 - accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.5824e-06 - accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.4980e-06 - accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.4683e-06 - accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.3726e-06 - accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.3281e-06 - accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.3132e-06 - accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.2639e-06 - accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.1930e-06 - accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.1603e-06 - accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.1211e-06 - accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.0797e-06 - accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 5.0468e-06 - accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.9704e-06 - accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.9299e-06 - accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.9012e-06 - accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.8929e-06 - accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.8187e-06 - accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.7768e-06 - accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.7695e-06 - accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.6829e-06 - accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.6793e-06 - accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.6144e-06 - accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.5907e-06 - accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.5685e-06 - accuracy: 1.0000\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.5310e-06 - accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.4758e-06 - accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.4419e-06 - accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.3982e-06 - accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.3829e-06 - accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "1459/1459 [==============================] - 2s 2ms/step - loss: 4.3506e-06 - accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.2812e-06 - accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.2812e-06 - accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.2584e-06 - accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.2191e-06 - accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.1990e-06 - accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "1459/1459 [==============================] - 1s 1ms/step - loss: 4.1707e-06 - accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.1293e-06 - accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.0903e-06 - accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.0625e-06 - accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.0120e-06 - accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 4.0118e-06 - accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.9827e-06 - accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.9535e-06 - accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.9356e-06 - accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.9022e-06 - accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.8672e-06 - accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.8465e-06 - accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.8221e-06 - accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.7844e-06 - accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.7628e-06 - accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.7397e-06 - accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.7148e-06 - accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.6935e-06 - accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.6674e-06 - accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.6477e-06 - accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.6363e-06 - accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.6011e-06 - accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.5659e-06 - accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.5460e-06 - accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.5486e-06 - accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "1459/1459 [==============================] - 1s 1ms/step - loss: 3.5183e-06 - accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.5096e-06 - accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.4666e-06 - accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.4685e-06 - accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "1459/1459 [==============================] - 1s 1ms/step - loss: 3.4405e-06 - accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.4252e-06 - accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "1459/1459 [==============================] - 1s 995us/step - loss: 3.4044e-06 - accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "1459/1459 [==============================] - 1s 1ms/step - loss: 3.3637e-06 - accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.3558e-06 - accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.3402e-06 - accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.3082e-06 - accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.2963e-06 - accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "1459/1459 [==============================] - 2s 1ms/step - loss: 3.2646e-06 - accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      " 314/1459 [=====>........................] - ETA: 1s - loss: 3.2265e-06 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e42091",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot loss during training\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.legend()\n",
    "# plot accuracy during training\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy')\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74239bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C17verificationmodel.pkl', 'wb') as f:\n",
    "    pickle.dump({'weights': model.get_weights(), 'history': history.history}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60337d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights and history from the file and evaluate the model\n",
    "with open('C17verificationmodel.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "model.set_weights(data['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c8cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b59df",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "# print the accuracy\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# create a chart of the model's predictions\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175cb92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.round(y_pred).flatten()\n",
    "\n",
    "# compute class-wise accuracy and confusion matrix\n",
    "class_0_correct = 0\n",
    "class_0_total = 0\n",
    "class_0_true_0 = 0\n",
    "class_0_false_1 = 0\n",
    "class_1_correct = 0\n",
    "class_1_total = 0\n",
    "class_1_true_1 = 0\n",
    "class_1_false_0 = 0\n",
    "for i in range(len(y_test)):\n",
    "    true_class = y_test[i]\n",
    "    pred_class = y_pred_classes[i]\n",
    "    if true_class == 0:\n",
    "        class_0_total += 1\n",
    "        if pred_class == 0:\n",
    "            class_0_correct += 1\n",
    "            class_0_true_0 += 1\n",
    "        else:\n",
    "            class_0_false_1 += 1\n",
    "    elif true_class == 1:\n",
    "        class_1_total += 1\n",
    "        if pred_class == 1:\n",
    "            class_1_correct += 1\n",
    "            class_1_true_1 += 1\n",
    "        else:\n",
    "            class_1_false_0 += 1\n",
    "\n",
    "class_0_accuracy = class_0_correct / class_0_total\n",
    "class_1_accuracy = class_1_correct / class_1_total\n",
    "\n",
    "print(\"Class 0:\")\n",
    "print(f\"  Total: {class_0_total}\")\n",
    "print(f\"  Correct: {class_0_correct}\")\n",
    "print(f\"  True 0: {class_0_true_0}\")\n",
    "print(f\"  False 1: {class_0_false_1}\")\n",
    "print(f\"  Accuracy: {class_0_accuracy}\")\n",
    "print(\"Class 1:\")\n",
    "print(f\"  Total: {class_1_total}\")\n",
    "print(f\"  Correct: {class_1_correct}\")\n",
    "print(f\"  True 1: {class_1_true_1}\")\n",
    "print(f\"  False 0: {class_1_false_0}\")\n",
    "print(f\"  Accuracy: {class_1_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f7549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
